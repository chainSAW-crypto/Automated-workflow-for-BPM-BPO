{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIkAk8IdjGfj",
        "outputId": "c931d985-e051-43bc-fd26-0cfae9693873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "generation_config = {\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 40,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generation_config=generation_config,\n",
        ")\n",
        "\n",
        "csv_path = \"/content/interest_metrics.csv\"\n",
        "interest_data = pd.read_csv(csv_path)\n",
        "interest_classes = []\n",
        "for index, row in interest_data.iterrows():\n",
        "    interest_classes.append(\n",
        "        f\"{row['Score']}: {row['Classification']}, {row['Description']}\"\n",
        "    )\n",
        "interest_descriptions = \"\\n\".join(interest_classes)\n",
        "\n",
        "\n",
        "def interest_classification_function(transcription):\n",
        "    chat_session = model.start_chat(history=[])\n",
        "    prompt = (\n",
        "        f\"You are an AI assistant trained to analyze customer interactions and classify queries based on interest. \"\n",
        "        f\"The interest is categorized into 10 classes. Here are the class definitions:\\n\\n\"\n",
        "        f\"{interest_descriptions}\\n\\n\"\n",
        "        f\"Your task is to analyze the following conversation, identify the customer's core query or concern, and classify it into one of these 10 interest classes. \"\n",
        "        f\"Output only the class number corresponding to the interest level.\\n\\n\"\n",
        "        f\"Conversation:\\n{transcription}\\n\\n\"\n",
        "        f\"Output:\"\n",
        "    )\n",
        "    response = chat_session.send_message(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "def requirment_extraction_function(transcription):\n",
        "    chat_session = model.start_chat(history=[])\n",
        "    prompt = (\n",
        "        f\"You are an AI assistant skilled in analyzing call-center dialogues. Your task is to extract the customer’s requirement from the conversation and summarize it concisely. \"\n",
        "        f\"Focus on the core need or request of the customer and make the requirement short and insightful, highlighting what the customer wants so we can determine how to assist them. \"\n",
        "        f\"Do not include any summaries or extra explanations, just provide the requirement.\\n\\n\"\n",
        "        f\"Conversation:\\n{transcription}\\n\\n\"\n",
        "        f\"Output:\"\n",
        "    )\n",
        "    response = chat_session.send_message(prompt)\n",
        "    return response.text\n",
        "\n",
        "\n",
        "def query_summarization_function(transcription):\n",
        "    chat_session = model.start_chat(history=[])\n",
        "    prompt = (\n",
        "        f\"You are a highly skilled AI assistant specializing in analyzing and summarizing call-center dialogues. Your role is to precisely identify and summarize the customer's primary query or concern. \"\n",
        "        f\"The conversation transcript between the customer and the agent is provided below in dialogue format (e.g., Customer: ..., Agent: ...). Carefully analyze the conversation, focusing on key details, and generate a clear, concise summary of the customer's main issue or request. \"\n",
        "        f\"Avoid generalizations and ensure the summary captures the specific query or concern expressed by the customer.\\n\\n\"\n",
        "        f\"Conversation:\\n{transcription}\\n\\n\"\n",
        "        f\"Output Format:\\n\"\n",
        "        f\"The customer is inquiring about [specific query or concern].\\n\\n\"\n",
        "        f\"Output:\"\n",
        "    )\n",
        "    response = chat_session.send_message(prompt)\n",
        "    return response.text\n",
        "\n"
      ],
      "metadata": {
        "id": "Riog7aWtmzhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def customer_info_extraction_function(transcription):\n",
        "    chat_session = model.start_chat(history=[])\n",
        "    prompt = (\n",
        "        f\"You are an AI assistant designed to extract customer's personal information from call center conversations. \"\n",
        "        f\"Your task is to identify the customer's name, phone number, email address, place they are calling from, and any other relevant personal details like their address or date of birth. \"\n",
        "        f\"Avoid extracting any work-related or requirements-related information. \"\n",
        "        f\"If any of this personal information is not explicitly mentioned in the conversation, simply respond with 'Not Found' for that specific field. \"\n",
        "        f\"\\n\\nConversation:\\n{transcription}\\n\\n\"\n",
        "        f\"Output Format:\\n\"\n",
        "        f\"{{'name': '[Customer Name]', 'customer_personal_info': {{'phone_number': '[Phone Number]', 'email': '[Email Address]', 'place': '[Place]', 'other_info': '[Other Personal Information]'}}}}\\n\\n\"  # Nested structure\n",
        "        f\"Output:\"\n",
        "    )\n",
        "    response = chat_session.send_message(prompt)\n",
        "    import json\n",
        "    try:\n",
        "        return json.loads(response.text)\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Warning: Could not decode JSON response: {response.text}\")\n",
        "        # Return default values with the desired structure\n",
        "        return {\"name\": \"Not Found\", \"customer_personal_info\": {\"phone_number\": \"Not Found\", \"email\": \"Not Found\", \"place\": \"Not Found\", \"other_info\": \"Not Found\"}}"
      ],
      "metadata": {
        "id": "bU-SnMiRsj4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transcription_file_path = \"/content/transcription.txt\"\n",
        "with open(transcription_file_path, \"r\") as file:\n",
        "    transcription = file.read()"
      ],
      "metadata": {
        "id": "Odw_Hm84o6ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from datetime import datetime\n",
        "\n",
        "interest_chain = RunnableParallel(interest_classification=interest_classification_function)\n",
        "requirment_extraction_chain = RunnableParallel(requirment_extraction=requirment_extraction_function)\n",
        "query_summarization_chain = RunnableParallel(query_summarization=query_summarization_function)\n",
        "\n",
        "combined_chain = RunnableParallel(\n",
        "    interest=interest_chain,\n",
        "    requirment=requirment_extraction_chain,\n",
        "    summary=query_summarization_chain,\n",
        "    customer_info=customer_info_extraction_function,\n",
        ")\n",
        "\n",
        "results = combined_chain.invoke({\"transcription\": transcription})\n",
        "output = {\n",
        "    \"id\": \"unique_id\",\n",
        "    \"summary\": results['summary']['query_summarization'],\n",
        "    \"requirment\": results['requirment']['requirment_extraction'],\n",
        "    \"InterestLVL\": results['interest']['interest_classification'],\n",
        "    \"Date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "    \"name\": results['customer_info']['name'],  # Customer's name\n",
        "    \"customer_personal_info\": {  # Other personal information\n",
        "        \"phone_number\": results['customer_info']['customer_personal_info']['phone_number'],\n",
        "        \"email\": results['customer_info']['customer_personal_info']['email'],\n",
        "        \"place\": results['customer_info']['customer_personal_info']['place'],\n",
        "        \"other_info\": results['customer_info']['customer_personal_info']['other_info']\n",
        "    }\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "U5O9_oWnmZaZ",
        "outputId": "1b354318-64f3-426d-aaf4-d35e357b648e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Could not decode JSON response: ```json\n",
            "{'name': 'Mr. Armando', 'customer_personal_info': {'phone_number': 'Not Found', 'email': 'Not Found', 'place': 'Not Found', 'other_info': 'Not Found'}}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EII6DLioe6H",
        "outputId": "177b6b48-b34e-4ae5-8c58-29901d8fa273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'unique_id', 'summary': 'The customer is inquiring about renting a car from the San José del Cabo International Airport (SJD) from the 21st to the 25th, ideally a Jeep Wrangler or similar SUV, and needs assistance determining pricing and availability from different rental car companies partnered with World Discovery Pacific.\\n', 'query': 'The customer requested to rent a car from the airport, specifying pick-up and drop-off dates and times, and inquired about the availability of specific car types and pricing, including taxes.\\n', 'urgencylvl': '5', 'elevation': 'yes', 'Date': '2024-12-14', 'name': 'Not Found', 'customer_personal_info': {'phone_number': 'Not Found', 'email': 'Not Found', 'place': 'Not Found', 'other_info': 'Not Found'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BvTDhL_pqlpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}